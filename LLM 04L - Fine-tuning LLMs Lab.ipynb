{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41e5acf5-7494-4b68-8ae5-a0b24df3c2c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9c49454-9ead-4ee6-98a6-ca5836d5d1fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 04L - Fine-tuning LLMs\n",
    "In this lab, we will apply the fine-tuning learnings from the demo Notebook. The aim of this lab is to fine-tune an instruction-following LLM.\n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Prepare a novel dataset\n",
    "1. Fine-tune the T5-small model to classify movie reviews.\n",
    "1. Leverage DeepSpeed to enhance training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:46:31.352135Z",
     "iopub.status.busy": "2023-07-15T08:46:31.351668Z",
     "iopub.status.idle": "2023-07-15T08:47:20.892866Z",
     "shell.execute_reply": "2023-07-15T08:47:20.891509Z",
     "shell.execute_reply.started": "2023-07-15T08:46:31.352088Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyspark --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:47:20.89566Z",
     "iopub.status.busy": "2023-07-15T08:47:20.895176Z",
     "iopub.status.idle": "2023-07-15T08:47:34.112511Z",
     "shell.execute_reply": "2023-07-15T08:47:34.111152Z",
     "shell.execute_reply.started": "2023-07-15T08:47:20.89561Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install delta-spark --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:47:34.116829Z",
     "iopub.status.busy": "2023-07-15T08:47:34.115773Z",
     "iopub.status.idle": "2023-07-15T08:47:44.622922Z",
     "shell.execute_reply": "2023-07-15T08:47:44.621643Z",
     "shell.execute_reply.started": "2023-07-15T08:47:34.116787Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"LLM 04L - Fine-tuning LLMs Lab\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "869ce68c-9120-4b3d-8ea8-c0decbf96f37",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-14T13:15:59.045426Z",
     "iopub.status.busy": "2023-07-14T13:15:59.044094Z",
     "iopub.status.idle": "2023-07-14T13:15:59.568866Z",
     "shell.execute_reply": "2023-07-14T13:15:59.567221Z",
     "shell.execute_reply.started": "2023-07-14T13:15:59.045344Z"
    }
   },
   "source": [
    "### THIS LAB REQUIRES THAT A GPU MACHINE AND RUNTIME IS UTILIZED."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7c5af7e-60c9-4c8b-a900-ed404e881dbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a2b2f3f-0e9e-4592-a0b0-4b70442d8052",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:47:44.632015Z",
     "iopub.status.busy": "2023-07-15T08:47:44.629494Z",
     "iopub.status.idle": "2023-07-15T08:47:59.154679Z",
     "shell.execute_reply": "2023-07-15T08:47:59.152553Z",
     "shell.execute_reply.started": "2023-07-15T08:47:44.63197Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install rouge_score==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:47:59.157231Z",
     "iopub.status.busy": "2023-07-15T08:47:59.156802Z",
     "iopub.status.idle": "2023-07-15T08:48:12.154261Z",
     "shell.execute_reply": "2023-07-15T08:48:12.152935Z",
     "shell.execute_reply.started": "2023-07-15T08:47:59.157191Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56497c3f-f54f-4539-a680-40c1821529a3",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:12.157772Z",
     "iopub.status.busy": "2023-07-15T08:48:12.15625Z",
     "iopub.status.idle": "2023-07-15T08:48:12.163182Z",
     "shell.execute_reply": "2023-07-15T08:48:12.162166Z",
     "shell.execute_reply.started": "2023-07-15T08:48:12.15773Z"
    }
   },
   "outputs": [],
   "source": [
    "#%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:12.165609Z",
     "iopub.status.busy": "2023-07-15T08:48:12.165115Z",
     "iopub.status.idle": "2023-07-15T08:48:13.173627Z",
     "shell.execute_reply": "2023-07-15T08:48:13.172213Z",
     "shell.execute_reply.started": "2023-07-15T08:48:12.165572Z"
    }
   },
   "outputs": [],
   "source": [
    "mkdir cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f86a913-0e01-4d40-8280-68f31bde17bc",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:13.176416Z",
     "iopub.status.busy": "2023-07-15T08:48:13.17599Z",
     "iopub.status.idle": "2023-07-15T08:48:13.257096Z",
     "shell.execute_reply": "2023-07-15T08:48:13.256155Z",
     "shell.execute_reply.started": "2023-07-15T08:48:13.176376Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6efceed8-2867-4fa5-bccd-8719804470f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a local temporary directory on the Driver. This will serve as a root directory for the intermediate model checkpoints created during the training process. The final model will be persisted to DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15fc78e7-0b23-47ef-8943-32d324edf543",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:13.259167Z",
     "iopub.status.busy": "2023-07-15T08:48:13.258596Z",
     "iopub.status.idle": "2023-07-15T08:48:13.299298Z",
     "shell.execute_reply": "2023-07-15T08:48:13.298439Z",
     "shell.execute_reply.started": "2023-07-15T08:48:13.25913Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "local_training_root = tmpdir.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e893ac2-b131-4772-95bc-5feeeec8178a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc41df12-bb90-4764-a267-01a16d49960b",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:13.304357Z",
     "iopub.status.busy": "2023-07-15T08:48:13.304015Z",
     "iopub.status.idle": "2023-07-15T08:48:41.606492Z",
     "shell.execute_reply": "2023-07-15T08:48:41.60551Z",
     "shell.execute_reply.started": "2023-07-15T08:48:13.304328Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a433e97-7cbc-4aed-b46c-e9e4de5da098",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 1: Data Preparation\n",
    "For the instruction-following use cases we need a dataset that consists of prompt/response pairs along with any contextual information that can be used as input when training the model. The [databricks/databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k) is one such dataset that provides high-quality, human-generated prompt/response pairs. \n",
    "\n",
    "Let's start by loading this dataset using the `load_dataset` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec7bf58f-92b7-47da-b706-15edebcc7421",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:41.608723Z",
     "iopub.status.busy": "2023-07-15T08:48:41.608267Z",
     "iopub.status.idle": "2023-07-15T08:48:43.394984Z",
     "shell.execute_reply": "2023-07-15T08:48:43.394066Z",
     "shell.execute_reply.started": "2023-07-15T08:48:41.608686Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "ds = load_dataset(\"databricks/databricks-dolly-15k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15084fed-43a5-4d13-851f-602498bd0b17",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:43.397297Z",
     "iopub.status.busy": "2023-07-15T08:48:43.396622Z",
     "iopub.status.idle": "2023-07-15T08:48:43.518351Z",
     "shell.execute_reply": "2023-07-15T08:48:43.516917Z",
     "shell.execute_reply.started": "2023-07-15T08:48:43.397258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_1(ds):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question1\"\n",
    "\n",
    "    assert str(ds.keys()) == \"dict_keys(['train'])\", \"Test NOT passed: `ds` should be of type `datasets.dataset_dict.DatasetDict`\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")\n",
    "\n",
    "dbTestQuestion4_1(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de2a1ce1-400c-4e95-acb6-30e1b1c83de3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 2: Select pre-trained model\n",
    "\n",
    "The model that we are going to fine-tune is [pythia-70m-deduped](https://huggingface.co/EleutherAI/pythia-70m). This model is one of a Pythia Suite of models that have been developed to support interpretability research.\n",
    "\n",
    "Let's define the pre-trained model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb4dfdbc-d622-4fca-91c1-a94886bbb4be",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:43.520353Z",
     "iopub.status.busy": "2023-07-15T08:48:43.519992Z",
     "iopub.status.idle": "2023-07-15T08:48:43.631973Z",
     "shell.execute_reply": "2023-07-15T08:48:43.63091Z",
     "shell.execute_reply.started": "2023-07-15T08:48:43.520319Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "model_checkpoint = \"EleutherAI/pythia-70m-deduped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db9178fa-eafe-4975-aa42-022f1505bc4d",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:43.63557Z",
     "iopub.status.busy": "2023-07-15T08:48:43.633329Z",
     "iopub.status.idle": "2023-07-15T08:48:43.74633Z",
     "shell.execute_reply": "2023-07-15T08:48:43.745123Z",
     "shell.execute_reply.started": "2023-07-15T08:48:43.635531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_2(model_checkpoint):\n",
    "    lesson, question = \"lesson4\", \"question2\"\n",
    "    \n",
    "    assert  model_checkpoint == \"EleutherAI/pythia-70m-deduped\", \"Test NOT passed: `model_checkpoint` should be `EleutherAI/pythia-70m-deduped`.\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")\n",
    "    \n",
    "dbTestQuestion4_2(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c37045ed-e0e2-4340-9185-df9d268af57d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 3: Load and Configure\n",
    "\n",
    "The next task is to load and configure the tokenizer for this model. The instruction-following process builds a body of text that contains the instruction, context input, and response values from the dataset. The body of text also includes some special tokens to identify the sections of the text. These tokens are generally configurable, and need to be added to the tokenizer.\n",
    "\n",
    "Let's go ahead and load the tokenizer for the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a5dbfb-fa6a-4754-938a-893d057eee9e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:43.748594Z",
     "iopub.status.busy": "2023-07-15T08:48:43.748096Z",
     "iopub.status.idle": "2023-07-15T08:48:44.512506Z",
     "shell.execute_reply": "2023-07-15T08:48:44.511405Z",
     "shell.execute_reply.started": "2023-07-15T08:48:43.748558Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load the tokenizer that was used for the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [\"### End\", \"### Instruction:\", \"### Response:\\n\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd015ef9-dd31-4a23-8309-5d2af6f3ffe5",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:44.514605Z",
     "iopub.status.busy": "2023-07-15T08:48:44.514218Z",
     "iopub.status.idle": "2023-07-15T08:48:44.63114Z",
     "shell.execute_reply": "2023-07-15T08:48:44.629964Z",
     "shell.execute_reply.started": "2023-07-15T08:48:44.514568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_3(tokenizer):\n",
    "    lesson, question = \"lesson4\", \"question3\"\n",
    "\n",
    "    assert str(type(tokenizer)) == \"<class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>\", \"Test NOT passed: `tokenizer` is not of type `transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast`\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")\n",
    "    \n",
    "dbTestQuestion4_3(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c994d0c8-5962-4893-9847-39f9be77649a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 4: Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33966a84-48bc-48bf-9d7d-0e8051dac30c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The `tokenize` method below builds the body of text for each prompt/response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b866a006-d815-4765-92ae-1316d6f137eb",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:44.633652Z",
     "iopub.status.busy": "2023-07-15T08:48:44.632868Z",
     "iopub.status.idle": "2023-07-15T08:48:44.752485Z",
     "shell.execute_reply": "2023-07-15T08:48:44.751598Z",
     "shell.execute_reply.started": "2023-07-15T08:48:44.633618Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_columns = [\"instruction\", \"response\", \"context\", \"category\"]\n",
    "\n",
    "\n",
    "def tokenize(x: dict, max_length: int = 1024) -> dict:\n",
    "    \"\"\"\n",
    "    For a dictionary example of instruction, response, and context a dictionary of input_id and attention mask is returned\n",
    "    \"\"\"\n",
    "    instr = x[\"instruction\"]\n",
    "    resp = x[\"response\"]\n",
    "    context = x[\"context\"]\n",
    "\n",
    "    instr_part = f\"### Instruction:\\n{instr}\"\n",
    "    context_part = \"\"\n",
    "    if context:\n",
    "        context_part = f\"\\nInput:\\n{context}\\n\"\n",
    "    resp_part = f\"### Response:\\n{resp}\"\n",
    "\n",
    "    text = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "{instr_part}\n",
    "{context_part}\n",
    "{resp_part}\n",
    "\n",
    "### End\n",
    "\"\"\"\n",
    "    return tokenizer(text, max_length=max_length, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "926c607e-f1b4-4ea2-aad9-3b52c7ad6c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's `tokenize` the Dolly training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0102435e-ee1b-4de7-b771-4694a56201ec",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:48:56.794157Z",
     "iopub.status.busy": "2023-07-15T08:48:56.793754Z",
     "iopub.status.idle": "2023-07-15T08:49:13.386289Z",
     "shell.execute_reply": "2023-07-15T08:49:13.385303Z",
     "shell.execute_reply.started": "2023-07-15T08:48:56.794111Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "tokenized_dataset = ds.map(tokenize, batched=False, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa49504d-48dd-4430-8473-7b4e11cd36cd",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:13.388668Z",
     "iopub.status.busy": "2023-07-15T08:49:13.388163Z",
     "iopub.status.idle": "2023-07-15T08:49:17.929547Z",
     "shell.execute_reply": "2023-07-15T08:49:17.928536Z",
     "shell.execute_reply.started": "2023-07-15T08:49:13.38863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_4(tokenized_dataset):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question4\"\n",
    "    \n",
    "    assert str(type(tokenized_dataset)) == \"<class 'datasets.dataset_dict.DatasetDict'>\", \"Test NOT passed: `tokenized_dataset` should be of type `datasets.dataset_dict.DatasetDict`\"\n",
    "    assert  len(tokenized_dataset[\"train\"][\"input_ids\"][0]) == len(tokenized_dataset[\"train\"][\"attention_mask\"][0]), \"Test NOT passed: For each entry the number of `input_ids` and `attention_masks` should be equal\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")    \n",
    "    \n",
    "dbTestQuestion4_4(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "319d2518-8604-4692-b868-d5f10cdf7b57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 5: Setup Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "392058b4-1328-4b66-a17f-53c3a9e1db40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To setup the fine-tuning process we need to define the `TrainingArguments`.\n",
    "\n",
    "Let's configure the training to have **10** training epochs (`num_train_epochs`) with a per device batch size of **8**. The optimizer (`optim`) to be used should be `adamw_torch`. Finally, the reporting (`report_to`) list should be set to *tensorboard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91b2320f-be9c-4240-b585-cf1bd46886b4",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:22.143927Z",
     "iopub.status.busy": "2023-07-15T08:49:22.143155Z",
     "iopub.status.idle": "2023-07-15T08:49:22.34737Z",
     "shell.execute_reply": "2023-07-15T08:49:22.346354Z",
     "shell.execute_reply.started": "2023-07-15T08:49:22.143892Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "checkpoint_name = \"test-trainer-lab\"\n",
    "local_checkpoint_path = os.path.join(local_training_root, checkpoint_name)\n",
    "training_args = TrainingArguments(\n",
    "    local_checkpoint_path,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "930d54bf-7852-4bd9-b858-de59469a907f",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:25.674982Z",
     "iopub.status.busy": "2023-07-15T08:49:25.674602Z",
     "iopub.status.idle": "2023-07-15T08:49:25.790943Z",
     "shell.execute_reply": "2023-07-15T08:49:25.789887Z",
     "shell.execute_reply.started": "2023-07-15T08:49:25.674953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_5(training_args):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question5\"\n",
    "    \n",
    "    assert training_args.num_train_epochs == 10, \"Test NOT passed: `num_train_epochs` should be 10.\"\n",
    "    assert str(type(training_args.optim)) == \"<enum 'OptimizerNames'>\", \"Test NOT passed: `optim` should be of type `OptimizerNames`.\"\n",
    "    \n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")  \n",
    "    \n",
    "dbTestQuestion4_5(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb322bf-9cd9-4931-bcba-ad671eefe034",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 6: AutoModelForCausalLM\n",
    "\n",
    "The pre-trained `pythia-70m-deduped` model can be loaded using the [AutoModelForCausalLM](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29013639-4913-4a5a-86d5-724a3399b502",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:41.154048Z",
     "iopub.status.busy": "2023-07-15T08:49:41.153633Z",
     "iopub.status.idle": "2023-07-15T08:49:43.645871Z",
     "shell.execute_reply": "2023-07-15T08:49:43.644869Z",
     "shell.execute_reply.started": "2023-07-15T08:49:41.154014Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load the pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3d4a9d4-ebca-4466-80a3-47f1d9239504",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:49:48.98593Z",
     "iopub.status.busy": "2023-07-15T08:49:48.985508Z",
     "iopub.status.idle": "2023-07-15T08:49:49.106605Z",
     "shell.execute_reply": "2023-07-15T08:49:49.105532Z",
     "shell.execute_reply.started": "2023-07-15T08:49:48.985897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_6(model):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question6\"\n",
    "\n",
    "    assert model.base_model_prefix == \"gpt_neox\", \"Test NOT passed: `base_model_prefix should be `gpt_neox`, reload your model checkpoint.\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")  \n",
    "    \n",
    "dbTestQuestion4_6(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90898a52-3722-4b9c-8511-9734b850b6c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 7: Initialize the Trainer\n",
    "\n",
    "Unlike the IMDB dataset used in the earlier Notebook, the Dolly dataset only contains a single *train* dataset. Let's go ahead and create a [`train_test_split`](https://huggingface.co/docs/datasets/v2.12.0/en/package_reference/main_classes#datasets.Dataset.train_test_split) of the train dataset.\n",
    "\n",
    "Also, let's initialize the [`Trainer`](https://huggingface.co/docs/transformers/main_classes/trainer) with model, training arguments, the train & test datasets, tokenizer, and data collator. Here we will use the [`DataCollatorForLanguageModeling`](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68b994ab-c7f8-4c50-9ccb-2e268614682e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:51:48.223992Z",
     "iopub.status.busy": "2023-07-15T08:51:48.223326Z",
     "iopub.status.idle": "2023-07-15T08:51:56.110054Z",
     "shell.execute_reply": "2023-07-15T08:51:56.108963Z",
     "shell.execute_reply.started": "2023-07-15T08:51:48.223951Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# used to assist the trainer in batching the data\n",
    "TRAINING_SIZE=6000\n",
    "SEED=42\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False, return_tensors=\"pt\", pad_to_multiple_of=8\n",
    ")\n",
    "split_dataset = tokenized_dataset[\"train\"].train_test_split(train_size=TRAINING_SIZE, shuffle=True, seed=SEED)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "037683be-fad4-4ee6-8c8c-8ca010268f6c",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:52:39.510317Z",
     "iopub.status.busy": "2023-07-15T08:52:39.509939Z",
     "iopub.status.idle": "2023-07-15T08:52:39.62727Z",
     "shell.execute_reply": "2023-07-15T08:52:39.626294Z",
     "shell.execute_reply.started": "2023-07-15T08:52:39.510285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_7(trainer):\n",
    "    lesson, question = \"lesson4\", \"question7\"\n",
    "\n",
    "    assert trainer.train_dataset.num_rows == 6000, \"Test NOT passed: The number of rows in the training data is not equal to `TRAINING_SIZE`.\"\n",
    "\n",
    "dbTestQuestion4_7(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0969801b-c05d-48d7-8697-293a55e6aea3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 8: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09568338-0942-4fc6-aa2c-b6b9203ed90c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Before starting the training process, let's turn on Tensorboard. This will allow us to monitor the training process as checkpoint logs are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b11d21d4-4522-4b36-876a-06415756239e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:52:40.883049Z",
     "iopub.status.busy": "2023-07-15T08:52:40.882261Z",
     "iopub.status.idle": "2023-07-15T08:52:40.996125Z",
     "shell.execute_reply": "2023-07-15T08:52:40.99513Z",
     "shell.execute_reply.started": "2023-07-15T08:52:40.883012Z"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard_display_dir = f\"{local_checkpoint_path}/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf628f4a-f832-4945-bd6f-77bfea3b3906",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:52:41.139826Z",
     "iopub.status.busy": "2023-07-15T08:52:41.138955Z",
     "iopub.status.idle": "2023-07-15T08:52:48.292094Z",
     "shell.execute_reply": "2023-07-15T08:52:48.290906Z",
     "shell.execute_reply.started": "2023-07-15T08:52:41.139783Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{tensorboard_display_dir}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caab993c-b30d-4091-85c2-181d1805a94f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Start the fine-tuning process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9613dbae-0e44-4b4d-bd4a-34a29e84e5ff",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T08:52:48.296598Z",
     "iopub.status.busy": "2023-07-15T08:52:48.296281Z",
     "iopub.status.idle": "2023-07-15T09:39:52.067504Z",
     "shell.execute_reply": "2023-07-15T09:39:52.066494Z",
     "shell.execute_reply.started": "2023-07-15T08:52:48.29657Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# invoke training - note this will take approx. 30min\n",
    "trainer.train()\n",
    "\n",
    "# save model to the local checkpoint\n",
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd726724-2b7e-4217-91cb-7448ae1668ed",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:41:11.623733Z",
     "iopub.status.busy": "2023-07-15T09:41:11.623289Z",
     "iopub.status.idle": "2023-07-15T09:41:11.757122Z",
     "shell.execute_reply": "2023-07-15T09:41:11.755966Z",
     "shell.execute_reply.started": "2023-07-15T09:41:11.623696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_8(trainer):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question8\"\n",
    "\n",
    "    assert trainer.state.epoch == 10.0, \"Test NOT passed: make sure to run your training for 10 epochs exactly.\"\n",
    "\n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")  \n",
    "\n",
    "dbTestQuestion4_8(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b6a107-530e-42e0-8e4f-2f2720f0d5d5",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:41:15.40967Z",
     "iopub.status.busy": "2023-07-15T09:41:15.409095Z",
     "iopub.status.idle": "2023-07-15T09:41:16.232481Z",
     "shell.execute_reply": "2023-07-15T09:41:16.231468Z",
     "shell.execute_reply.started": "2023-07-15T09:41:15.409618Z"
    }
   },
   "outputs": [],
   "source": [
    "# persist the fine-tuned model to DBFS\n",
    "final_model_path = f\"../working/cache/llm04_fine_tuning/{checkpoint_name}\"\n",
    "trainer.save_model(output_dir=final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e2e2081-7560-48fa-bb4a-d3f07bd481c5",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:41:18.966999Z",
     "iopub.status.busy": "2023-07-15T09:41:18.966634Z",
     "iopub.status.idle": "2023-07-15T09:41:19.592397Z",
     "shell.execute_reply": "2023-07-15T09:41:19.591194Z",
     "shell.execute_reply.started": "2023-07-15T09:41:18.96697Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd452229-5165-4948-b0e9-0a8698d6039e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:41:25.926642Z",
     "iopub.status.busy": "2023-07-15T09:41:25.926266Z",
     "iopub.status.idle": "2023-07-15T09:41:27.368935Z",
     "shell.execute_reply": "2023-07-15T09:41:27.367691Z",
     "shell.execute_reply.started": "2023-07-15T09:41:25.92661Z"
    }
   },
   "outputs": [],
   "source": [
    "fine_tuned_model = AutoModelForCausalLM.from_pretrained(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0400310e-324b-4df8-9a61-70b32f78c1e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Recall that the model was trained using a body of text that contained an instruction and its response. A similar body of text, or prompt, needs to be provided when testing the model. The prompt that is provided only contains an instruction though. The model will `generate` the response accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac21796b-29d8-4039-81f9-97504bc3a28e",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:43:21.35625Z",
     "iopub.status.busy": "2023-07-15T09:43:21.355294Z",
     "iopub.status.idle": "2023-07-15T09:43:21.474645Z",
     "shell.execute_reply": "2023-07-15T09:43:21.47353Z",
     "shell.execute_reply.started": "2023-07-15T09:43:21.356213Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_prompt(instr: str, max_length: int = 1024) -> dict:\n",
    "    text = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instr}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    return tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "\n",
    "\n",
    "def to_response(prediction):\n",
    "    decoded = tokenizer.decode(prediction)\n",
    "    # extract the Response from the decoded sequence\n",
    "    m = re.search(r\"#+\\s*Response:\\s*(.+?)#+\\s*End\", decoded, flags=re.DOTALL)\n",
    "    res = \"Failed to find response\"\n",
    "    if m:\n",
    "        res = m.group(1).strip()\n",
    "    else:\n",
    "        m = re.search(r\"#+\\s*Response:\\s*(.+)\", decoded, flags=re.DOTALL)\n",
    "        if m:\n",
    "            res = m.group(1).strip()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T09:44:08.406672Z",
     "iopub.status.busy": "2023-07-15T09:44:08.40628Z",
     "iopub.status.idle": "2023-07-15T09:44:08.520871Z",
     "shell.execute_reply": "2023-07-15T09:44:08.519851Z",
     "shell.execute_reply.started": "2023-07-15T09:44:08.406639Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c69b856-12eb-4120-8867-587deb667d12",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:44:09.071228Z",
     "iopub.status.busy": "2023-07-15T09:44:09.070854Z",
     "iopub.status.idle": "2023-07-15T09:49:41.671337Z",
     "shell.execute_reply": "2023-07-15T09:49:41.670274Z",
     "shell.execute_reply.started": "2023-07-15T09:44:09.071197Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "res = []\n",
    "for i in range(100):\n",
    "    instr = ds[\"train\"][i][\"instruction\"]\n",
    "    resp = ds[\"train\"][i][\"response\"]\n",
    "    inputs = to_prompt(instr)\n",
    "    pred = fine_tuned_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"].to(device),\n",
    "        attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    "    res.append((instr, resp, to_response(pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c5a63e-3bb5-453d-8642-2ce8ed98c667",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:49:41.674068Z",
     "iopub.status.busy": "2023-07-15T09:49:41.673665Z",
     "iopub.status.idle": "2023-07-15T09:49:41.855555Z",
     "shell.execute_reply": "2023-07-15T09:49:41.854352Z",
     "shell.execute_reply.started": "2023-07-15T09:49:41.674031Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(res, columns=[\"instruction\", \"response\", \"generated\"])\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e2f106c-6e26-4d71-a602-ae3cdbb46de2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**CONGRATULATIONS**\n",
    "\n",
    "You have just taken the first step toward fine-tuning your own slimmed down version of [Dolly](https://github.com/databrickslabs/dolly)! \n",
    "\n",
    "Unfortunately, it does not seem to be too generative at the moment. Perhaps, with some additional training and data the model could be more capable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d4e4fc6-4d02-4795-8065-0b2dbb488c67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Question 9: Evaluation\n",
    "\n",
    "Although the current model is under-trained, it is worth evaluating the responses to get a general sense of how far off the model is at this point.\n",
    "\n",
    "Let's compute the ROGUE metrics between the reference response and the generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7d202c0-992c-47f4-bc3f-9592dedb1198",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:54:53.965526Z",
     "iopub.status.busy": "2023-07-15T09:54:53.965023Z",
     "iopub.status.idle": "2023-07-15T09:54:54.471026Z",
     "shell.execute_reply": "2023-07-15T09:54:54.469905Z",
     "shell.execute_reply.started": "2023-07-15T09:54:53.965428Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_rouge_score(generated, reference):\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores on a batch of articles.\n",
    "\n",
    "    This is a convenience function wrapping Hugging Face `rouge_score`,\n",
    "    which expects sentences to be separated by newlines.\n",
    "\n",
    "    :param generated: Summaries (list of strings) produced by the model\n",
    "    :param reference: Ground-truth summaries (list of strings) for comparison\n",
    "    \"\"\"\n",
    "    generated_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in generated]\n",
    "    reference_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in reference]\n",
    "    return rouge_score.compute(\n",
    "        predictions=generated_with_newlines,\n",
    "        references=reference_with_newlines,\n",
    "        use_stemmer=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf5570ec-61b2-41ce-87bc-c23022a99f89",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:54:54.474023Z",
     "iopub.status.busy": "2023-07-15T09:54:54.47327Z",
     "iopub.status.idle": "2023-07-15T09:54:56.151594Z",
     "shell.execute_reply": "2023-07-15T09:54:56.150526Z",
     "shell.execute_reply.started": "2023-07-15T09:54:54.473984Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "rouge_scores = compute_rouge_score(pdf[\"generated\"], pdf[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T09:54:57.645975Z",
     "iopub.status.busy": "2023-07-15T09:54:57.645596Z",
     "iopub.status.idle": "2023-07-15T09:54:57.778738Z",
     "shell.execute_reply": "2023-07-15T09:54:57.777634Z",
     "shell.execute_reply.started": "2023-07-15T09:54:57.645943Z"
    }
   },
   "outputs": [],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e7c1f22-1ca1-4b28-81f6-77f147a13972",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:55:03.082583Z",
     "iopub.status.busy": "2023-07-15T09:55:03.082156Z",
     "iopub.status.idle": "2023-07-15T09:55:03.202888Z",
     "shell.execute_reply": "2023-07-15T09:55:03.201504Z",
     "shell.execute_reply.started": "2023-07-15T09:55:03.082551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "def dbTestQuestion4_9(rouge_scores):\n",
    "    # modified so it works on kaggle\n",
    "    lesson, question = \"lesson4\", \"question9\"\n",
    "\n",
    "    assert type(rouge_scores) == dict, \"Test NOT passed: `rouge_scores should be a dict, check your scoring answer.\"\n",
    "    \n",
    "    print(f\"{lesson}, {question}\")\n",
    "    print(\"All Tests passed...\")\n",
    "\n",
    "dbTestQuestion4_9(rouge_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6da21761-b9a0-4e4f-b483-be1d64aa3f85",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Clean up Classroom\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee64845d-5529-4951-915c-24e9840acbd8",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-07-15T09:55:48.729504Z",
     "iopub.status.busy": "2023-07-15T09:55:48.729104Z",
     "iopub.status.idle": "2023-07-15T09:55:48.846729Z",
     "shell.execute_reply": "2023-07-15T09:55:48.845731Z",
     "shell.execute_reply.started": "2023-07-15T09:55:48.729447Z"
    }
   },
   "outputs": [],
   "source": [
    "# not needed on kaggle\n",
    "# tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45529d6b-c7c3-40d0-922f-0a637948dfac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Submit your Results (edX Verified Only)\n",
    "\n",
    "To get credit for this lab, click the submit button in the top right to report the results. If you run into any issues, click `Run` -> `Clear state and run all`, and make sure all tests have passed before re-submitting. If you accidentally deleted any tests, take a look at the notebook's version history to recover them or reload the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa5446a6-3bb3-476a-a3ee-2d66b2ef430e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
